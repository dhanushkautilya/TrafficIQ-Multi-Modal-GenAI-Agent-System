# ğŸš¨ TrafficIQ: AI-Powered Vehicle Identification System

![Python 3.11](https://img.shields.io/badge/python-3.11-blue) ![License: MIT](https://img.shields.io/badge/license-MIT-green) ![Status: Alpha](https://img.shields.io/badge/status-alpha-orange)

## What is TrafficIQ?

**TrafficIQ** is an AI system that automatically analyzes traffic camera images to:
- ğŸ” Identify vehicles (make, model, year, color, body type)
- ğŸ“¸ Extract license plates via OCR
- âš ï¸ Check watchlists for suspected vehicles (BOLO)
- ğŸ“‹ Create priority-ranked cases for investigators

Think of it as an intelligent traffic camera assistant that helps law enforcement process images faster and more accurately.

### Why TrafficIQ?

| Challenge | Solution |
|-----------|----------|
| Manual analysis is slow | Automated AI predictions in ~200ms |
| High error rates | ML models trained on thousands of images |
| Poor metadata | Structured JSON cases with full audit trail |
| Development complexity | Works locally (no GCP needed) + Cloud Run ready |

## Architecture

## How It Works (3-Step Pipeline)

```
Traffic Camera Image
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Vehicle Analysis             â”‚
â”‚ â€¢ Make, model, year, color detected  â”‚
â”‚ â€¢ Confidence level calculated        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: License Plate Extraction     â”‚
â”‚ â€¢ OCR if image quality is poor       â”‚
â”‚ â€¢ Skip if prediction already strong  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Watchlist Check + Priority   â”‚
â”‚ â€¢ Check BOLO database for matches    â”‚
â”‚ â€¢ Assign priority (P0/P1/P2)         â”‚
â”‚ â€¢ Create case record                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    Case Record
(Ready for Investigator)
```

## System Layers

**API Layer** (FastAPI)
- REST endpoints for predictions and case creation
- Automatic documentation at `/docs`
- Ready to deploy on Cloud Run

**Intelligence Layer** (Agent Router)
- Orchestrates the 3-step pipeline
- Makes decisions based on confidence thresholds
- Logs every decision for audit trail

**Tools Layer** (Integrations)
- Vertex AI (Google's ML model) - real or mock
- Plate OCR (pattern matching)
- BOLO watchlist (demo version)
- Case management (local storage)

## Key Features âœ¨

| Feature | What It Does |
|---------|-------------|
| ğŸ¤– **Smart Vehicle Detection** | Identifies make, model, year, color, body type |
| ğŸ“· **Adaptive OCR** | Auto-extracts license plates when needed |
| ğŸš¨ **Watchlist Integration** | Cross-references BOLO database for alerts |
| ğŸ“Š **Automatic Prioritization** | Ranks cases as P0 (critical), P1 (medium), P2 (routine) |
| ğŸ’¾ **Structured Evidence** | Saves complete JSON audit trail for each case |
| ğŸ§ª **Mock Mode** | Works offline without GCP account |
| â˜ï¸ **Cloud Ready** | Deploy to Google Cloud Run with one command |
| ğŸ“ˆ **Built-in Evaluation** | Metrics, confusion matrices, calibration analysis |
| ğŸ”’ **Type-Safe** | Pydantic models prevent data errors |
| ğŸ“ **Structured Logs** | JSON logging for production visibility

## âš¡ Quick Start (5 Minutes)

### Step 1: Clone & Setup

```bash
# Clone the repository
git clone https://github.com/dhanushkautilya/TrafficIQ-Multi-Modal-GenAI-Agent-System.git
cd TrafficIQ-Multi-Modal-GenAI-Agent-System/trafficIQ

# Create Python environment
python3.11 -m venv venv
source venv/bin/activate          # Windows: venv\Scripts\activate
```

### Step 2: Install Dependencies

```bash
# Development mode (includes testing tools)
pip install -e ".[dev]"

# Takes ~1 minute on first install
```

### Step 3: Start the API

```bash
# Run the server
uvicorn app.api.main:app --reload

# Output will show:
# "Uvicorn running on http://127.0.0.1:8000"
```

### Step 4: Test It! ğŸ‰

Open a **new terminal** and try:

```bash
# âœ“ Health check
curl http://localhost:8000/health

# âœ“ Analyze a vehicle
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"image_uri": "gs://bucket/car_image.jpg"}'

# âœ“ Full pipeline (predict + check watchlist + create case)
curl -X POST http://localhost:8000/agent/run \
  -H "Content-Type: application/json" \
  -d '{
    "image_uri": "gs://bucket/car_image.jpg",
    "location": "Downtown Intersection"
  }'
```

**That's it!** ğŸš€ The API is now working with mock predictions (no GCP account needed).

---

## ğŸ“– Common Tasks

### Run Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov=eval

# Run specific test
pytest tests/test_api.py -v
```

### Run Evaluation

```bash
# Evaluate model on sample dataset
python -m eval.evaluate

# View results
cat artifacts/eval_report.md
```

### View API Documentation

Open in browser: **http://localhost:8000/docs**

(Auto-generated Swagger UI with live testing)

### Check Logs

```bash
# Enable debug logging
LOG_LEVEL=debug uvicorn app.api.main:app --reload

# JSON format for production
JSON_LOGGING=true uvicorn app.api.main:app
```

### Configure for Production

```bash
# Create .env file
cp .env.example .env

# Edit key settings:
ENVIRONMENT=production
LOG_LEVEL=info
USE_VERTEX=false  # Change to true for real Vertex AI

# For Google Cloud
GCP_PROJECT=my-project
VERTEX_ENDPOINT_ID=projects/xxx/locations/xxx/endpoints/xxx
```

## Project Structure

```
trafficIQ/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                    # FastAPI application
â”‚   â”‚   â”œâ”€â”€ main.py             # App initialization
â”‚   â”‚   â””â”€â”€ routes.py           # Endpoint definitions
â”‚   â”œâ”€â”€ agent/                  # Orchestration logic
â”‚   â”‚   â”œâ”€â”€ router.py           # Main agent
â”‚   â”‚   â”œâ”€â”€ policy.py           # Decision policies
â”‚   â”‚   â””â”€â”€ prompts.py          # LLM prompts
â”‚   â”œâ”€â”€ common/                 # Shared utilities
â”‚   â”‚   â”œâ”€â”€ config.py           # Configuration management
â”‚   â”‚   â”œâ”€â”€ logging.py          # Structured logging
â”‚   â”‚   â”œâ”€â”€ schemas.py          # Pydantic models
â”‚   â”‚   â””â”€â”€ utils.py            # Helper functions
â”‚   â””â”€â”€ tools/                  # External integrations
â”‚       â”œâ”€â”€ vertex_client.py     # Vertex AI interface
â”‚       â”œâ”€â”€ ocr_client.py        # Plate extraction
â”‚       â”œâ”€â”€ bolo_client.py       # Watchlist lookup
â”‚       â”œâ”€â”€ evidence.py          # Evidence packets
â”‚       â””â”€â”€ case_client.py       # Case management
â”œâ”€â”€ eval/                       # Evaluation module
â”‚   â”œâ”€â”€ evaluate.py             # Evaluation pipeline
â”‚   â”œâ”€â”€ metrics.py              # Metrics calculation
â”‚   â”œâ”€â”€ dataset_schema.md       # Dataset format docs
â”‚   â””â”€â”€ sample_data.jsonl       # Sample evaluation data
â”œâ”€â”€ tests/                      # Unit tests
â”‚   â”œâ”€â”€ test_api.py             # API endpoint tests
â”‚   â”œâ”€â”€ test_router.py          # Agent/policy tests
â”‚   â””â”€â”€ test_tools.py           # Tools layer tests
â”œâ”€â”€ infra/                      # Deployment artifacts
â”‚   â”œâ”€â”€ Dockerfile.api          # Container image for API
â”‚   â”œâ”€â”€ Dockerfile.agent        # Container image for batch
â”‚   â”œâ”€â”€ cloudrun_deploy.md      # Cloud Run deployment guide
â”‚   â””â”€â”€ terraform_stub.md       # Infrastructure as Code
â”œâ”€â”€ architecture/
â”‚   â””â”€â”€ system_design.mmd       # Mermaid system diagram
â”œâ”€â”€ pyproject.toml              # Project configuration
â”œâ”€â”€ .env.example                # Environment template
â””â”€â”€ README.md                   # This file
```

## ğŸ¯ Decision Logic & Priorities

### How Priority is Assigned

The system uses a simple, transparent ruleset:

| Condition | Result | Meaning |
|-----------|--------|---------|
| **BOLO Match** + Confidence â‰¥ 70% | **P0** | High-priority alert - known suspect, high confidence |
| **BOLO Match** + Confidence < 70% | **P1** | Medium-priority alert - known suspect, lower confidence |
| **No BOLO Match** | **P2** | Routine case - no watchlist match |

### When OCR is Automatically Used

The system checks the image and uses OCR (plate extraction) if:
- ğŸŒ™ Image is at night
- ğŸŒ«ï¸ Image is blurry
- ğŸŒ§ï¸ Image is rainy
- ğŸ“‰ Vehicle confidence is below 70%

Otherwise, it skips OCR to save time.

## ğŸŒ Using Real Vertex AI

### For Development (Optional)

By default, TrafficIQ uses **mock predictions** (deterministic, works offline). To use real Vertex AI:

#### 1. Install GCP Libraries

```bash
pip install -e ".[gcp]"
```

#### 2. Setup GCP Account

```bash
# Authenticate
gcloud auth application-default login

# Set project
gcloud config set project YOUR_PROJECT_ID
```

#### 3. Update Environment

```bash
# Edit .env
USE_VERTEX=true
GCP_PROJECT=your-project-id
VERTEX_ENDPOINT_ID=projects/YOUR_PROJECT/locations/us-central1/endpoints/YOUR_ENDPOINT_ID
```

#### 4. Restart API

```bash
uvicorn app.api.main:app --reload
```

The API will now use real Vertex AI predictions instead of mocks. **All code is the same!**

---

## ğŸ“Š Evaluation & Metrics

### Run Evaluation

```bash
python -m eval.evaluate
```

This analyzes the sample dataset and generates a report.

### View Results

```bash
cat artifacts/eval_report.md
```

**Output includes:**
- Accuracy by vehicle make
- Confusion matrix (top makes)
- Calibration metric (ECE)
- Sample predictions

---

## ğŸ“ Project Structure

```
trafficIQ/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/              # Flask-like FastAPI server
â”‚   â”œâ”€â”€ agent/            # Decision logic & orchestration
â”‚   â”œâ”€â”€ tools/            # Integrations (Vertex AI, OCR, BOLO, etc.)
â”‚   â””â”€â”€ common/           # Shared utilities, schemas, logging
â”œâ”€â”€ eval/                 # Evaluation & metrics
â”œâ”€â”€ tests/                # Unit tests (pytest)
â”œâ”€â”€ infra/                # Docker, Cloud Run, Terraform
â”œâ”€â”€ pyproject.toml        # Dependencies & config
â”œâ”€â”€ .env.example          # Environment template
â””â”€â”€ README.md             # This file
```

---

## ğŸš€ Deploy to Google Cloud

### Option 1: Cloud Run (Easiest)

```bash
# Deploy from source
gcloud run deploy trafficiq-api \
  --source . \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated
```

Your API is now live! ğŸ‰

### Option 2: Docker

```bash
# Build image
docker build -f infra/Dockerfile.api -t trafficiq:latest .

# Run container
docker run -p 8000:8000 -e USE_VERTEX=false trafficiq:latest
```

### Option 3: Kubernetes

See `infra/cloudrun_deploy.md` for detailed K8s manifests.

---

## ğŸ§ª Testing

### Run All Tests

```bash
pytest -v
```

### Run Specific Test

```bash
pytest tests/test_api.py::test_health_check -v
```

### With Coverage

```bash
pytest --cov=app --cov=eval --cov-report=html
```

Opens `htmlcov/index.html` with detailed coverage report.

---

## ğŸ” Troubleshooting

To use actual Vertex AI predictions instead of mocks:



## ğŸ” Troubleshooting

### âŒ "ModuleNotFoundError: No module named 'xyz'"

**Fix:** Make sure you installed with `-e ".[dev]"`

```bash
pip install -e ".[dev]"
```

### âŒ "Vertex AI connection failed"

This happens if `USE_VERTEX=true` but you didn't install GCP libraries.

**Fix:**
```bash
pip install -e ".[gcp]"
gcloud auth application-default login
```

Or just use mock mode:
```bash
# In .env
USE_VERTEX=false
```

### âŒ "Port 8000 already in use"

Another process is using the port.

**Fix:** Use a different port
```bash
uvicorn app.api.main:app --port 8001
```

### âŒ "Mock predictions are not deterministic"

**Check:** Same image URI should give same result. If not, something else is wrong.

```bash
# Should return same prediction
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"image_uri": "gs://bucket/same_image.jpg"}'

# Run twice, compare results
```

### âŒ "API returns 500 error"

Check the logs:

```bash
# Enable debug logging
LOG_LEVEL=debug uvicorn app.api.main:app --reload

# Look for error messages
```

### âŒ "BOLO lookups always match"

Watchlist is too broad. Adjust thresholds in `app/agent/policy.py`:

```python
P0_THRESHOLDS = {"bolo_match": True, "min_confidence": 0.85}  # Stricter
P1_THRESHOLDS = {"bolo_match": True, "min_confidence": 0.70}
```

---

## ğŸ“Š Performance

Typical latencies on Google Cloud Run (2 CPU, 4GB RAM):

| Operation | Time | Notes |
|-----------|------|-------|
| Health check | 5ms | No computation |
| Vehicle prediction (mock) | 20ms | Hash-based |
| Vehicle prediction (Vertex AI) | 150-300ms | Network + inference |
| OCR extraction | 30ms | Pattern matching |
| Full pipeline (mock) | 200ms | All steps combined |
| Full pipeline (Vertex AI) | 400-600ms | End-to-end |

---

## ğŸ“š Project Configuration

### Environment Variables

All settings are controlled by `.env` file. Copy the example:

```bash
cp .env.example .env
```

**Key Variables:**

```env
# Server
ENVIRONMENT=development          # or "production"
LOG_LEVEL=info                   # debug, info, warning, error
API_TITLE=TrafficIQ
API_VERSION=0.1.0

# ML Model
USE_VERTEX=false                 # false = mock, true = real Vertex AI
GCP_PROJECT=my-gcp-project
VERTEX_ENDPOINT_ID=projects/xxx/locations/xxx/endpoints/xxx

# Storage
ARTIFACTS_PATH=./artifacts      # Where to save evidence packets
USE_GCS=false                    # false = local (./artifacts), true = Google Cloud Storage

# External Services
BOLO_SERVICE_URL=http://localhost:8001
CASE_SERVICE_URL=http://localhost:8002
```

### Policy Thresholds

Edit `app/agent/policy.py` to adjust decision logic:

```python
PolicyConfig(
    # When to use OCR fallback
    MIN_VEHICLE_CONFIDENCE_FOR_SKIP_OCR=0.70,
    
    # Priority assignment
    P0_THRESHOLDS={"bolo_match": True, "min_confidence": 0.70},
    P1_THRESHOLDS={"bolo_match": True, "min_confidence": 0.50},
    P2_THRESHOLDS={"bolo_match": False},
)
```

---

## ğŸ¤ Contributing

Found a bug? Want to add a feature? Here's how:

1. Fork the repo
2. Create a feature branch: `git checkout -b feature/amazing-thing`
3. Make your changes and add tests
4. Run tests: `pytest -v`
5. Commit: `git commit -m "Add amazing thing"`
6. Push: `git push origin feature/amazing-thing`
7. Open a Pull Request

---

## ğŸ—ºï¸ Roadmap

**In Progress:**
- [ ] Real Vertex AI fine-tuning pipeline
- [ ] WebSocket streaming endpoints
- [ ] Advanced BOLO database integration

**Planned:**
- [ ] Multi-model ensemble (vehicle + plate + pedestrian)
- [ ] Real-time Grafana dashboard
- [ ] Model explainability (LIME/SHAP)
- [ ] Automated retraining pipeline
- [ ] VIN detection
- [ ] Terraform infrastructure modules

---

## ğŸ“„ License

MIT License - See LICENSE file

---

## ğŸ’¬ Get Help

- ğŸ“– **Docs:** Read `/dev /docs` endpoint (auto-generated)
- ğŸ› **Issues:** GitHub Issues
- ğŸ’­ **Questions:** GitHub Discussions
- ğŸ“§ **Email:** dev@trafficiq.local

---

## â­ About TrafficIQ

**TrafficIQ** makes it easy for law enforcement to:
- âœ… Analyze images in seconds (not manually)
- âœ… Identify high-priority cases automatically
- âœ… Build an audit trail for each investigation
- âœ… Work offline or in the cloud

**Built with:**
- ğŸ Python 3.11
- âš¡ FastAPI (modern API framework)
- ğŸ¤– Vertex AI (Google's ML platform)
- ğŸ“¦ Pydantic (type safety)
- ğŸ§ª Pytest (testing)
- â˜ï¸ Cloud Run (serverless deployment)

**Made with â¤ï¸ for public safety** ğŸš¨

```
      ğŸš— ğŸš™ ğŸš• ğŸšŒ ğŸš
    TrafficIQ - AI for Traffic
    Keep roads safer, faster
```
