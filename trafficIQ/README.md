# ğŸš¨ TrafficIQ: AI-Powered Vehicle Identification System

![Python 3.11](https://img.shields.io/badge/python-3.11-blue) ![License: MIT](https://img.shields.io/badge/license-MIT-green) ![Status: Alpha](https://img.shields.io/badge/status-alpha-orange)

## What is TrafficIQ?

**TrafficIQ** is an AI system that automatically analyzes traffic camera images to:
- ğŸ” Identify vehicles (make, model, year, color, body type)
- ğŸ“¸ Extract license plates via OCR
- âš ï¸ Check watchlists for suspected vehicles (BOLO)
- ğŸ“‹ Create priority-ranked cases for investigators

Think of it as an intelligent traffic camera assistant that helps law enforcement process images faster and more accurately.

### Why TrafficIQ?

| Challenge | Solution |
|-----------|----------|
| Manual analysis is slow | Automated AI predictions in ~200ms |
| High error rates | ML models trained on thousands of images |
| Poor metadata | Structured JSON cases with full audit trail |
| Development complexity | Works locally (no GCP needed) + Cloud Run ready |

## Architecture

## How It Works (3-Step Pipeline)

```
Traffic Camera Image
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Vehicle Analysis             â”‚
â”‚ â€¢ Make, model, year, color detected  â”‚
â”‚ â€¢ Confidence level calculated        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: License Plate Extraction     â”‚
â”‚ â€¢ OCR if image quality is poor       â”‚
â”‚ â€¢ Skip if prediction already strong  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Watchlist Check + Priority   â”‚
â”‚ â€¢ Check BOLO database for matches    â”‚
â”‚ â€¢ Assign priority (P0/P1/P2)         â”‚
â”‚ â€¢ Create case record                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    Case Record
(Ready for Investigator)
```

## System Layers

**API Layer** (FastAPI)
- REST endpoints for predictions and case creation
- Automatic documentation at `/docs`
- Ready to deploy on Cloud Run

**Intelligence Layer** (Agent Router)
- Orchestrates the 3-step pipeline
- Makes decisions based on confidence thresholds
- Logs every decision for audit trail

**Tools Layer** (Integrations)
- Vertex AI (Google's ML model) - real or mock
- Plate OCR (pattern matching)
- BOLO watchlist (demo version)
- Case management (local storage)

## Key Features âœ¨

| Feature | What It Does |
|---------|-------------|
| ğŸ¤– **Smart Vehicle Detection** | Identifies make, model, year, color, body type |
| ğŸ“· **Adaptive OCR** | Auto-extracts license plates when needed |
| ğŸš¨ **Watchlist Integration** | Cross-references BOLO database for alerts |
| ğŸ“Š **Automatic Prioritization** | Ranks cases as P0 (critical), P1 (medium), P2 (routine) |
| ğŸ’¾ **Structured Evidence** | Saves complete JSON audit trail for each case |
| ğŸ§ª **Mock Mode** | Works offline without GCP account |
| â˜ï¸ **Cloud Ready** | Deploy to Google Cloud Run with one command |
| ğŸ“ˆ **Built-in Evaluation** | Metrics, confusion matrices, calibration analysis |
| ğŸ”’ **Type-Safe** | Pydantic models prevent data errors |
| ğŸ“ **Structured Logs** | JSON logging for production visibility

## âš¡ Quick Start (5 Minutes)

### Step 1: Clone & Setup

```bash
# Clone the repository
git clone https://github.com/dhanushkautilya/TrafficIQ-Multi-Modal-GenAI-Agent-System.git
cd TrafficIQ-Multi-Modal-GenAI-Agent-System/trafficIQ

# Create Python environment
python3.11 -m venv venv
source venv/bin/activate          # Windows: venv\Scripts\activate
```

### Step 2: Install Dependencies

```bash
# Development mode (includes testing tools)
pip install -e ".[dev]"

# Takes ~1 minute on first install
```

### Step 3: Start the API

```bash
# Run the server
uvicorn app.api.main:app --reload

# Output will show:
# "Uvicorn running on http://127.0.0.1:8000"
```

### Step 4: Test It! ğŸ‰

Open a **new terminal** and try:

```bash
# âœ“ Health check
curl http://localhost:8000/health

# âœ“ Analyze a vehicle
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{"image_uri": "gs://bucket/car_image.jpg"}'

# âœ“ Full pipeline (predict + check watchlist + create case)
curl -X POST http://localhost:8000/agent/run \
  -H "Content-Type: application/json" \
  -d '{
    "image_uri": "gs://bucket/car_image.jpg",
    "location": "Downtown Intersection"
  }'
```

**That's it!** ğŸš€ The API is now working with mock predictions (no GCP account needed).

---

## ğŸ“– Common Tasks

## ğŸ“– Common Tasks

### Run Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov=eval

# Run specific test
pytest tests/test_api.py -v
```

### Run Evaluation

```bash
# Evaluate model on sample dataset
python -m eval.evaluate

# View results
cat artifacts/eval_report.md
```

### View API Documentation

Open in browser: **http://localhost:8000/docs**

(Auto-generated Swagger UI with live testing)

### Check Logs

```bash
# Enable debug logging
LOG_LEVEL=debug uvicorn app.api.main:app --reload

# JSON format for production
JSON_LOGGING=true uvicorn app.api.main:app
```

### Configure for Production

```bash
# Create .env file
cp .env.example .env

# Edit key settings:
ENVIRONMENT=production
LOG_LEVEL=info
USE_VERTEX=false  # Change to true for real Vertex AI

# For Google Cloud
GCP_PROJECT=my-project
VERTEX_ENDPOINT_ID=projects/xxx/locations/xxx/endpoints/xxx
```

## Configuration

### Environment Variables

```bash
# Application
ENVIRONMENT=development              # development | production
LOG_LEVEL=info                        # debug, info, warning, error
JSON_LOGGING=true                     # JSON structured logs
API_TITLE=TrafficIQ
API_VERSION=0.1.0

# Vertex AI / GCP
USE_VERTEX=false                      # false = mock, true = real
GCP_PROJECT=my-gcp-project
GCP_REGION=us-central1
VERTEX_ENDPOINT_ID=projects/.../endpoints/...
VERTEX_MODEL_NAME=gemma-3n-tuned-vehicles

# Storage
ARTIFACTS_PATH=./artifacts
USE_GCS=false                         # false = local, true = GCS
GCS_BUCKET=my-trafficiq-bucket

# External Services
BOLO_SERVICE_URL=http://localhost:8001
CASE_SERVICE_URL=http://localhost:8002
DEBUG=false
```

### Policy Configuration

Adjustable thresholds in `app/agent/policy.py`:

```python
PolicyConfig(
    MIN_VEHICLE_CONFIDENCE_FOR_SKIP_OCR=0.70,  # Confidence needed to skip OCR
    MIN_PLATE_CONFIDENCE_FOR_BOLO=0.60,        # Minimum plate confidence
    NIGHT_QUALITY_PENALTY=0.15,                # Confidence reduction for night
    BLUR_QUALITY_PENALTY=0.20,                 # Confidence reduction for blur
)
```

Priority Rules:
- **P0**: BOLO match + vehicle confidence â‰¥ 0.70
- **P1**: BOLO match + vehicle confidence < 0.70
- **P2**: No BOLO match

## Project Structure

```
trafficIQ/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                    # FastAPI application
â”‚   â”‚   â”œâ”€â”€ main.py             # App initialization
â”‚   â”‚   â””â”€â”€ routes.py           # Endpoint definitions
â”‚   â”œâ”€â”€ agent/                  # Orchestration logic
â”‚   â”‚   â”œâ”€â”€ router.py           # Main agent
â”‚   â”‚   â”œâ”€â”€ policy.py           # Decision policies
â”‚   â”‚   â””â”€â”€ prompts.py          # LLM prompts
â”‚   â”œâ”€â”€ common/                 # Shared utilities
â”‚   â”‚   â”œâ”€â”€ config.py           # Configuration management
â”‚   â”‚   â”œâ”€â”€ logging.py          # Structured logging
â”‚   â”‚   â”œâ”€â”€ schemas.py          # Pydantic models
â”‚   â”‚   â””â”€â”€ utils.py            # Helper functions
â”‚   â””â”€â”€ tools/                  # External integrations
â”‚       â”œâ”€â”€ vertex_client.py     # Vertex AI interface
â”‚       â”œâ”€â”€ ocr_client.py        # Plate extraction
â”‚       â”œâ”€â”€ bolo_client.py       # Watchlist lookup
â”‚       â”œâ”€â”€ evidence.py          # Evidence packets
â”‚       â””â”€â”€ case_client.py       # Case management
â”œâ”€â”€ eval/                       # Evaluation module
â”‚   â”œâ”€â”€ evaluate.py             # Evaluation pipeline
â”‚   â”œâ”€â”€ metrics.py              # Metrics calculation
â”‚   â”œâ”€â”€ dataset_schema.md       # Dataset format docs
â”‚   â””â”€â”€ sample_data.jsonl       # Sample evaluation data
â”œâ”€â”€ tests/                      # Unit tests
â”‚   â”œâ”€â”€ test_api.py             # API endpoint tests
â”‚   â”œâ”€â”€ test_router.py          # Agent/policy tests
â”‚   â””â”€â”€ test_tools.py           # Tools layer tests
â”œâ”€â”€ infra/                      # Deployment artifacts
â”‚   â”œâ”€â”€ Dockerfile.api          # Container image for API
â”‚   â”œâ”€â”€ Dockerfile.agent        # Container image for batch
â”‚   â”œâ”€â”€ cloudrun_deploy.md      # Cloud Run deployment guide
â”‚   â””â”€â”€ terraform_stub.md       # Infrastructure as Code
â”œâ”€â”€ architecture/
â”‚   â””â”€â”€ system_design.mmd       # Mermaid system diagram
â”œâ”€â”€ pyproject.toml              # Project configuration
â”œâ”€â”€ .env.example                # Environment template
â””â”€â”€ README.md                   # This file
```

## Switching to Real Vertex AI

To use actual Vertex AI predictions instead of mocks:

### 1. Setup GCP Project

```bash
# Create project and enable APIs
gcloud projects create trafficiq-prod
gcloud config set project trafficiq-prod
gcloud services enable aiplatform.googleapis.com storage-api.googleapis.com
```

### 2. Create Vertex AI Endpoint

```bash
# Deploy your Gemma 3n fine-tuned model
# (Assuming you have a trained model checkpoint)
gcloud ai models create \
  --region=us-central1 \
  --display-name=gemma-3n-vehicles \
  --framework=pytorch

# Create endpoint
gcloud ai endpoints create \
  --region=us-central1 \
  --display-name=trafficiq-inference
```

### 3. Update Environment

```bash
# In .env or Cloud Run environment variables
USE_VERTEX=true
GCP_PROJECT=trafficiq-prod
VERTEX_ENDPOINT_ID=projects/YOUR_PROJECT/locations/us-central1/endpoints/YOUR_ENDPOINT
```

### 4. Install GCP Dependencies

```bash
pip install -e ".[gcp]"
```

### 5. Authenticate

```bash
# For local development
gcloud auth application-default login

# For Cloud Run, ensure service account has roles:
# - roles/aiplatform.user
# - roles/storage.objectAdmin
```

The agent will automatically call real Vertex endpoints instead of using mock predictions.

## Evaluation

### Run Evaluation

```bash
python -m eval.evaluate

# Output: artifacts/eval_report.md
```

### Sample Metrics

The evaluation module computes:

- **Accuracy**: Overall prediction accuracy by vehicle make
- **Per-Class Accuracy**: Broken down by make (Honda, Toyota, etc.)
- **Confusion Matrix**: Top-5 makes
- **ECE (Expected Calibration Error)**: Confidence calibration metric (lower is better)

### Example Report

```markdown
# TrafficIQ Evaluation Report

## Summary
- Dataset Size: 10 samples
- Successful Predictions: 10/10
- Evaluation Date: 2024-01-15 14:30:00

## Overall Metrics
- **Accuracy**: 0.8000 (80.00%)
- **ECE (Calibration)**: 0.0532
- **Precision (macro)**: 0.0000
- **Recall (macro)**: 0.0000
- **F1-Score (macro)**: 0.0000

## Per-Class Accuracy (Vehicle Makes)
| Make        | Accuracy           |
|-------------|-------------------|
| Honda       | 1.0000 (100.00%)  |
| Toyota      | 0.5000 (50.00%)   |
| Ford        | 1.0000 (100.00%)  |
```

## Deployment

### Docker Build

```bash
docker build -f infra/Dockerfile.api -t trafficiq:latest .
docker run -p 8000:8000 \
  -e USE_VERTEX=false \
  -e ENVIRONMENT=production \
  trafficiq:latest
```

### Cloud Run Deployment

```bash
# See detailed guide in infra/cloudrun_deploy.md

# Quick deploy
gcloud run deploy trafficiq-api \
  --source . \
  --platform managed \
  --region us-central1 \
  --memory 4Gi \
  --cpu 2 \
  --allow-unauthenticated
```

### Kubernetes (GKE)

Example manifest:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: trafficiq-api
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: api
        image: gcr.io/PROJECT/trafficiq:latest
        ports:
        - containerPort: 8000
        env:
        - name: USE_VERTEX
          value: "true"
        resources:
          limits:
            cpu: 2
            memory: 4Gi
```

## Testing

### Unit Tests

```bash
# Run all tests
pytest -v

# Run specific module
pytest tests/test_api.py -v

# With coverage report
pytest --cov=app --cov=eval --cov-report=html
```

### Integration Tests

```bash
# Start API server in one terminal
uvicorn app.api.main:app --reload

# Run integration tests in another
pytest tests/test_api.py::TestIntegration -v
```

### Load Testing (Locust)

```bash
# Install locust
pip install locust

# Run load test
locust -f tests/locustfile.py --host=http://localhost:8000
```

## Monitoring & Logging

### Local Logging

```bash
# Set log level
LOG_LEVEL=debug python -m uvicorn app.api.main:app

# JSON structured logs (production)
JSON_LOGGING=true uvicorn app.api.main:app
```

### Cloud Logging (Cloud Run)

Logs automatically appear in Google Cloud Logging:

```bash
gcloud run logs read trafficiq-api --limit=50
```

### Key Metrics to Monitor

```python
# In logs, watch for:
- vehicle_prediction_confidence < 0.60  # Low confidence predictions
- ocr_fallback_used=true                # Frequent OCR fallbacks indicate image quality issues
- processing_time > 500ms               # Slow responses
- bolo_match=true                       # Watchlist matches
- priority=P0                           # Critical matches
```

## Troubleshooting

### Mock Predictions Are Not Deterministic

**Issue**: Same image URI produces different predictions.

**Solution**: Ensure `USE_VERTEX=false`. Mock mode uses MD5 hash of URI.

```bash
# Verify config
curl http://localhost:8000/health
```

### Vertex AI Connection Fails

**Issue**: `google-cloud-aiplatform` not installed.

**Solution**:
```bash
pip install -e ".[gcp]"
gcloud auth application-default login
```

### BOLO Lookups Always Match

**Issue**: Too many false positives on watchlist.

**Solution**: Adjust policy thresholds in `app/agent/policy.py`:

```python
PolicyConfig(
    P0_THRESHOLDS={"bolo_match": True, "min_confidence": 0.85},  # Higher threshold
    P1_THRESHOLDS={"bolo_match": True, "min_confidence": 0.70},
)
```

### High Memory Usage

**Issue**: API server consuming too much RAM.

**Solution**: 
- Reduce batch size
- Implement request caching
- Scale horizontally on Cloud Run

```bash
gcloud run update trafficiq-api --memory 8Gi --max-instances 100
```

## Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## Performance Benchmarks

Running on Google Cloud Run (2 CPU, 4GB RAM):

| Operation | Latency | Notes |
|-----------|---------|-------|
| Health Check | ~5ms | No computation |
| Vehicle Prediction (mock) | ~20ms | Hash-based |
| Vehicle Prediction (Vertex) | ~150-300ms | Network + model |
| OCR Extraction | ~30ms | Pattern matching |
| BOLO Lookup | ~15ms | Hardcoded match |
| Full Agent Pipeline (mock) | ~200ms | All steps |
| Full Agent Pipeline (Vertex) | ~400-600ms | End-to-end |

## Next Steps & Roadmap

- [ ] Implement real Vertex AI fine-tuning pipeline
- [ ] Add WebSocket endpoints for streaming analysis
- [ ] Implement BOLO database abstraction (PostgreSQL, MongoDB)
- [ ] Add multi-model blend (vehical + plate + pedestrian detectors)
- [ ] Implement feedback loop for model retraining
- [ ] Add real-time dashboard (Grafana/Streamlit)
- [ ] Expand to other vehicle attributes (license plate, VIN detection)
- [ ] Implement explainability (LIME/SHAP) for predictions
- [ ] Add automated testing (CI/CD pipeline)
- [ ] Create Terraform modules for reproducible infrastructure

## License

MIT License - See LICENSE file for details

## Support

For issues, questions, or contributions:

- **GitHub Issues**: [Report bugs here](https://github.com/your-org/trafficiq/issues)
- **Discussions**: [Ask questions here](https://github.com/your-org/trafficiq/discussions)
- **Email**: dev@trafficiq.local

## Authors

- TrafficIQ Team

---

**Built with â¤ï¸ for traffic law enforcement and public safety**
